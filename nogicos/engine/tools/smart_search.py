# -*- coding: utf-8 -*-
"""
NogicOS Smart Search - Cursor é£æ ¼çš„æ™ºèƒ½æœç´¢
å®ç° 2æ¬¡ LLM è°ƒç”¨çš„é«˜æ•ˆæœç´¢æµç¨‹
"""

import os
import json
import time
import asyncio
from typing import Dict, Any, List, Optional
from datetime import datetime

import aiohttp
import anthropic

from engine.observability import get_logger

logger = get_logger("smart_search")


class SmartSearch:
    """
    Cursor é£æ ¼çš„æ™ºèƒ½æœç´¢
    
    æµç¨‹:
    0. Intent Detection - åˆ¤æ–­æ˜¯å¦éœ€è¦æœç´¢ (å¯é€‰ï¼Œå¿«é€Ÿåˆ¤æ–­)
    1. Query Optimization - LLM ä¼˜åŒ–ç”¨æˆ·è¾“å…¥ä¸ºæœç´¢ query
    2. Tavily Search - è°ƒç”¨ API è·å–ç»“æœ
    3. Result Synthesis - LLM æ•´åˆç»“æœå¹¶ç”Ÿæˆå›ç­”
    
    è°ƒç”¨ç²¾ç¡®åº¦ï¼š
    - éœ€è¦æœç´¢: æ—¶æ•ˆæ€§é—®é¢˜ã€äº‹å®æŸ¥è¯¢ã€æœ€æ–°ä¿¡æ¯
    - ä¸éœ€è¦æœç´¢: ä»£ç é—®é¢˜ã€æ•°å­¦è®¡ç®—ã€é€šç”¨çŸ¥è¯†ã€é—²èŠ
    """
    
    # å¼ºåˆ¶ä¸æœç´¢çš„æ¨¡å¼ (æœ€é«˜ä¼˜å…ˆçº§)
    FORCE_NO_SEARCH = [
        "è¿™æ®µä»£ç ", "è¿™ä¸ªæ–‡ä»¶", "è¿™ä¸ªå‡½æ•°", "è¿™ä¸ªç±»",
        "å¸®æˆ‘å†™", "å¸®æˆ‘å®ç°", "å¸®æˆ‘ä¿®", "å¸®æˆ‘debug",
    ]
    
    # éœ€è¦æœç´¢çš„æ¨¡å¼ (é«˜ä¼˜å…ˆçº§)
    SEARCH_PATTERNS = [
        # æ—¶æ•ˆæ€§
        "æœ€æ–°", "2025", "2024", "ä»Šå¤©", "æœ€è¿‘", "ç°åœ¨",
        # äº‹å®æŸ¥è¯¢ (é€šç”¨æ¦‚å¿µ)
        "æ˜¯ä»€ä¹ˆæ„æ€", "æœ‰å“ªäº›", "åŒºåˆ«", "å¯¹æ¯”", "æ€ä¹ˆç”¨",
        # æ˜ç¡®æœç´¢
        "æœç´¢", "æŸ¥ä¸€ä¸‹", "æ‰¾ä¸€ä¸‹", "çœ‹çœ‹",
        # äº§å“/å…¬å¸/æ¦‚å¿µ
        "YC", "Cursor", "OpenAI", "Anthropic", "Google",
        "é‡å­", "AI", "äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ ", "åŒºå—é“¾",
    ]
    
    # ä¸éœ€è¦æœç´¢çš„æ¨¡å¼ (ä½ä¼˜å…ˆçº§)
    NO_SEARCH_PATTERNS = [
        # ä»£ç ç›¸å…³
        "å†™ä»£ç ", "å†™ä¸€ä¸ª", "å®ç°ä¸€ä¸ª", "å‡½æ•°", "class ", "def ", "import ",
        "debug", "ä¿®å¤", "æŠ¥é”™", "error", "bug", "ä»£ç ",
        # æ•°å­¦è®¡ç®—
        "è®¡ç®—ä¸€ä¸‹", "ç­‰äºå¤šå°‘", "åŠ å‡ä¹˜é™¤",
        # é—²èŠ
        "ä½ å¥½", "è°¢è°¢", "å†è§", "å¸®å¸®æˆ‘", "å¯ä»¥å—",
    ]
    
    def __init__(self):
        # è·å– API keys
        self.tavily_api_key = os.environ.get("TAVILY_API_KEY")
        self.anthropic_api_key = os.environ.get("ANTHROPIC_API_KEY")
        
        if not self.tavily_api_key:
            try:
                from api_keys import TAVILY_API_KEY
                self.tavily_api_key = TAVILY_API_KEY
            except ImportError:
                pass
        
        if not self.anthropic_api_key:
            try:
                from api_keys import ANTHROPIC_API_KEY
                self.anthropic_api_key = ANTHROPIC_API_KEY
            except ImportError:
                pass
        
        # ä¸ Cursor ä¿æŒä¸€è‡´ï¼Œä½¿ç”¨ Opus 4.5 ä¿è¯è´¨é‡
        self.optimizer_model = "claude-opus-4-5-20250514"  # è´¨é‡ä¼˜å…ˆ
        self.client = anthropic.AsyncAnthropic(api_key=self.anthropic_api_key) if self.anthropic_api_key else None
    
    def should_search(self, user_input: str) -> tuple[bool, str]:
        """
        å¿«é€Ÿåˆ¤æ–­æ˜¯å¦éœ€è¦æœç´¢ï¼ˆæ—  LLM è°ƒç”¨ï¼ŒåŸºäºè§„åˆ™ï¼‰
        
        ä¼˜å…ˆçº§ï¼šå¼ºåˆ¶ä¸æœç´¢ > æœç´¢æ¨¡å¼ > ä¸æœç´¢æ¨¡å¼ > é»˜è®¤è§„åˆ™
        
        è¿”å›: (æ˜¯å¦æœç´¢, åŸå› )
        """
        input_lower = user_input.lower()
        
        # 0. æœ€é«˜ä¼˜å…ˆçº§ï¼šå¼ºåˆ¶ä¸æœç´¢ï¼ˆä»£ç ä¸Šä¸‹æ–‡ç›¸å…³ï¼‰
        for pattern in self.FORCE_NO_SEARCH:
            if pattern.lower() in input_lower:
                return False, f"ä»£ç ä¸Šä¸‹æ–‡: {pattern}"
        
        # 1. æ£€æŸ¥æ˜¯å¦æ˜ç¡®éœ€è¦æœç´¢
        for pattern in self.SEARCH_PATTERNS:
            if pattern.lower() in input_lower:
                return True, f"åŒ¹é…æœç´¢æ¨¡å¼: {pattern}"
        
        # 2. æ£€æŸ¥æ˜¯å¦æ˜ç¡®ä¸éœ€è¦æœç´¢
        for pattern in self.NO_SEARCH_PATTERNS:
            if pattern.lower() in input_lower:
                return False, f"åŒ¹é…ä¸æœç´¢æ¨¡å¼: {pattern}"
        
        # 3. é»˜è®¤è§„åˆ™ï¼šé—®å¥æˆ–çŸ­æ–‡æœ¬ -> æœç´¢
        if "?" in user_input or "ï¼Ÿ" in user_input:
            return True, "ç–‘é—®å¥ï¼Œé»˜è®¤æœç´¢"
        
        if len(user_input) < 30:
            return True, "çŸ­æŸ¥è¯¢ï¼Œé»˜è®¤æœç´¢"
        
        return False, "é•¿æ–‡æœ¬ä¸”æ— æœç´¢å…³é”®è¯ï¼Œé»˜è®¤ä¸æœç´¢"
        
    async def optimize_query(self, user_input: str) -> str:
        """
        Step 1: ç”¨ LLM å°†ç”¨æˆ·è¾“å…¥ä¼˜åŒ–ä¸ºæœç´¢ query
        
        ç›®æ ‡:
        - æå–å…³é”®è¯
        - æ·»åŠ æ—¶é—´é™å®š (å¦‚ 2025)
        - æ‰©å±•åŒä¹‰è¯
        - ç§»é™¤æ— æ•ˆè¯
        
        è€—æ—¶ç›®æ ‡: < 1ç§’
        """
        if not self.client:
            logger.warning("No Anthropic client, returning original query")
            return user_input
        
        # æç®€ prompt åŠ é€Ÿç”Ÿæˆ
        prompt = f"""Convert to search query. Output ONLY the query, no explanation.
If time-sensitive, add "2025". Use English keywords if helpful.

Input: {user_input}
Query:"""

        try:
            start = time.time()
            response = await self.client.messages.create(
                model=self.optimizer_model,
                max_tokens=100,
                messages=[{"role": "user", "content": prompt}]
            )
            optimized = response.content[0].text.strip()
            logger.info(f"[QueryOptimize] {time.time()-start:.2f}s: '{user_input}' â†’ '{optimized}'")
            return optimized
        except Exception as e:
            logger.error(f"Query optimization failed: {e}")
            return user_input
    
    async def tavily_search(self, query: str, max_results: int = 5) -> Dict[str, Any]:
        """
        Step 2: è°ƒç”¨ Tavily API æœç´¢
        
        ç‰¹æ€§:
        - auto_parameters: è‡ªåŠ¨ä¼˜åŒ–æœç´¢å‚æ•°
        - include_answer: è·å– AI ç”Ÿæˆçš„ç­”æ¡ˆ
        
        è€—æ—¶ç›®æ ‡: 0.5-1.5ç§’
        """
        if not self.tavily_api_key:
            return {"error": "TAVILY_API_KEY not configured"}
        
        try:
            start = time.time()
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    "https://api.tavily.com/search",
                    json={
                        "api_key": self.tavily_api_key,
                        "query": query,
                        "max_results": max_results,
                        "include_answer": True,
                        "include_raw_content": False,
                        "search_depth": "basic",  # basic æ›´å¿«
                    },
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    response.raise_for_status()
                    data = await response.json()
                    logger.info(f"[TavilySearch] {time.time()-start:.2f}s: {len(data.get('results', []))} results")
                    return data
        except Exception as e:
            logger.error(f"Tavily search failed: {e}")
            return {"error": str(e)}
    
    async def synthesize_results(
        self, 
        user_input: str, 
        search_results: Dict[str, Any]
    ) -> str:
        """
        Step 3: ç”¨ LLM æ•´åˆæœç´¢ç»“æœ
        
        ç›®æ ‡:
        - ç®€æ´å›ç­”ç”¨æˆ·é—®é¢˜
        - æä¾›æ¥æºå¼•ç”¨
        - çªå‡ºå…³é”®ä¿¡æ¯
        
        è€—æ—¶ç›®æ ‡: 1-2ç§’
        """
        if not self.client:
            # æ—  LLM æ—¶è¿”å›åŸå§‹ç»“æœ
            answer = search_results.get("answer", "")
            results = search_results.get("results", [])
            
            output = answer + "\n\n**æ¥æº:**\n"
            for i, r in enumerate(results[:3], 1):
                output += f"{i}. [{r.get('title', 'Link')}]({r.get('url', '')})\n"
            return output
        
        # æ„å»ºç²¾ç®€ä¸Šä¸‹æ–‡
        tavily_answer = search_results.get("answer", "")
        results = search_results.get("results", [])
        
        # åªå–å‰3ä¸ªç»“æœï¼Œæ¯ä¸ªåªå–100å­—ç¬¦
        context_parts = [f"AIæ‘˜è¦: {tavily_answer}"]
        for i, r in enumerate(results[:3], 1):
            context_parts.append(f"{i}. {r.get('title', '')} - {r.get('content', '')[:100]}")
        context = "\n".join(context_parts)
        
        # æç®€ prompt - å¼ºåˆ¶ä¸­æ–‡
        prompt = f"""æ ¹æ®æœç´¢ç»“æœç”¨ä¸­æ–‡ç®€æ´å›ç­”ã€‚æœ«å°¾é™„æ¥æºé“¾æ¥ã€‚

é—®é¢˜: {user_input}
{context}
å›ç­”:"""

        try:
            start = time.time()
            response = await self.client.messages.create(
                model=self.optimizer_model,
                max_tokens=300,  # é™åˆ¶è¾“å‡ºé•¿åº¦åŠ é€Ÿ
                messages=[{"role": "user", "content": prompt}]
            )
            synthesized = response.content[0].text.strip()
            logger.info(f"[Synthesize] {time.time()-start:.2f}s")
            return synthesized
        except Exception as e:
            logger.error(f"Result synthesis failed: {e}")
            # Fallback to raw answer
            return search_results.get("answer", f"æœç´¢å®Œæˆï¼Œä½†æ•´åˆå¤±è´¥: {e}")
    
    async def search(
        self, 
        user_input: str, 
        max_results: int = 5,
        force_search: bool = False  # å¼ºåˆ¶æœç´¢ï¼Œè·³è¿‡åˆ¤æ–­
    ) -> Dict[str, Any]:
        """
        å®Œæ•´çš„æ™ºèƒ½æœç´¢æµç¨‹
        
        è¿”å›:
        {
            "success": bool,
            "should_search": bool,  # æ˜¯å¦æ‰§è¡Œäº†æœç´¢
            "skip_reason": str,     # å¦‚æœè·³è¿‡ï¼ŒåŸå› æ˜¯ä»€ä¹ˆ
            "answer": str,          # æ•´åˆåçš„å›ç­”
            "sources": list,        # æ¥æºåˆ—è¡¨
            "timing": {...}
        }
        """
        total_start = time.time()
        timing = {}
        
        # Step 0: åˆ¤æ–­æ˜¯å¦éœ€è¦æœç´¢
        if not force_search:
            should, reason = self.should_search(user_input)
            if not should:
                timing["total_ms"] = (time.time() - total_start) * 1000
                return {
                    "success": True,
                    "should_search": False,
                    "skip_reason": reason,
                    "answer": None,
                    "sources": [],
                    "timing": timing
                }
        
        try:
            # Step 1: ä¼˜åŒ– Query
            step1_start = time.time()
            optimized_query = await self.optimize_query(user_input)
            timing["optimize_query_ms"] = (time.time() - step1_start) * 1000
            
            # Step 2: Tavily æœç´¢
            step2_start = time.time()
            search_results = await self.tavily_search(optimized_query, max_results)
            timing["search_ms"] = (time.time() - step2_start) * 1000
            
            if "error" in search_results:
                return {
                    "success": False,
                    "error": search_results["error"],
                    "timing": timing
                }
            
            # Step 3: æ•´åˆç»“æœ
            step3_start = time.time()
            final_answer = await self.synthesize_results(user_input, search_results)
            timing["synthesize_ms"] = (time.time() - step3_start) * 1000
            
            timing["total_ms"] = (time.time() - total_start) * 1000
            
            # æå–æ¥æº
            sources = []
            for r in search_results.get("results", [])[:5]:
                sources.append({
                    "title": r.get("title", ""),
                    "url": r.get("url", ""),
                    "snippet": r.get("content", "")[:150]
                })
            
            return {
                "success": True,
                "should_search": True,
                "query": user_input,
                "optimized_query": optimized_query,
                "answer": final_answer,
                "tavily_answer": search_results.get("answer", ""),
                "sources": sources,
                "timing": timing
            }
            
        except Exception as e:
            timing["total_ms"] = (time.time() - total_start) * 1000
            logger.error(f"Smart search failed: {e}")
            return {
                "success": False,
                "error": str(e),
                "timing": timing
            }


# Singleton instance
_smart_search: Optional[SmartSearch] = None

def get_smart_search() -> SmartSearch:
    global _smart_search
    if _smart_search is None:
        _smart_search = SmartSearch()
    return _smart_search


async def smart_search(query: str, max_results: int = 5, force_search: bool = False) -> Dict[str, Any]:
    """Convenience function for smart search"""
    return await get_smart_search().search(query, max_results, force_search)


# CLI for testing
if __name__ == "__main__":
    import sys
    sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
    from api_keys import setup_env
    setup_env()
    
    async def test():
        searcher = SmartSearch()
        
        test_queries = [
            "AI æœ€æ–°è¿›å±•",
            "Cursor IDE æ€ä¹ˆç”¨",
            "ä»Šå¤©å¤©æ°”",
        ]
        
        for q in test_queries:
            print(f"\n{'='*60}")
            print(f"Query: {q}")
            print('='*60)
            
            result = await searcher.search(q)
            
            if result["success"]:
                print(f"\nğŸ“ ä¼˜åŒ–å Query: {result['optimized_query']}")
                print(f"\nğŸ“Š å›ç­”:\n{result['answer']}")
                print(f"\nâ±ï¸ è€—æ—¶:")
                for k, v in result["timing"].items():
                    print(f"   {k}: {v:.0f}ms")
            else:
                print(f"âŒ å¤±è´¥: {result.get('error')}")
    
    asyncio.run(test())

